{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/alik604/cyber-security/blob/master/Intrusion-Detection/UNSW_NB15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fl-cPhNxn6QU"
   },
   "source": [
    "# UNSW-NB15\n",
    "> 95.5% Accuracy in binary classification\n",
    "\n",
    "## References \n",
    "MLP with pytorch at end\n",
    " \n",
    " * Data source: https://www.unsw.adfa.edu.au/unsw-canberra-cyber/cybersecurity/ADFA-NB15-Datasets/\n",
    " * Sample/starter code: https://github.com/Nir-J/ML-Projects/blob/master/UNSW-Network_Packet_Classification/unsw.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mlxtend catboost xgboost lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Lx1Zh6UUU-ov"
   },
   "outputs": [],
   "source": [
    "BINARY = False # binary classification or multi-class classification \n",
    "%config IPCompleter.greedy=True\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as matplot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import *\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import regularizers\n",
    "\n",
    "from sklearn.metrics import *\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder,normalize\n",
    "\n",
    "\n",
    "import xgboost, lightgbm\n",
    "from mlxtend.classifier import EnsembleVoteClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2Kvca3apvAc"
   },
   "source": [
    "# Preprocessing (transformation/scaling) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vjw9JrARVJ23"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('https://raw.githubusercontent.com/Nir-J/ML-Projects/master/UNSW-Network_Packet_Classification/UNSW_NB15_training-set.csv')\n",
    "test = pd.read_csv('https://raw.githubusercontent.com/Nir-J/ML-Projects/master/UNSW-Network_Packet_Classification/UNSW_NB15_testing-set.csv')\n",
    "combined_data = pd.concat([train, test]).drop(['id'], axis=1) # We will reSplit later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "      <th>attack_cat</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.121478</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>FIN</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>258</td>\n",
       "      <td>172</td>\n",
       "      <td>74.087490</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.649902</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>FIN</td>\n",
       "      <td>14</td>\n",
       "      <td>38</td>\n",
       "      <td>734</td>\n",
       "      <td>42014</td>\n",
       "      <td>78.473372</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.623129</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>FIN</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>364</td>\n",
       "      <td>13186</td>\n",
       "      <td>14.170161</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.681642</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>628</td>\n",
       "      <td>770</td>\n",
       "      <td>13.677108</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.449454</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>FIN</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>534</td>\n",
       "      <td>268</td>\n",
       "      <td>33.373826</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       dur proto service state  spkts  dpkts  sbytes  dbytes       rate  \\\n",
       "0   1  0.121478   tcp       -   FIN      6      4     258     172  74.087490   \n",
       "1   2  0.649902   tcp       -   FIN     14     38     734   42014  78.473372   \n",
       "2   3  1.623129   tcp       -   FIN      8     16     364   13186  14.170161   \n",
       "3   4  1.681642   tcp     ftp   FIN     12     12     628     770  13.677108   \n",
       "4   5  0.449454   tcp       -   FIN     10      6     534     268  33.373826   \n",
       "\n",
       "   ...  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  ct_ftp_cmd  \\\n",
       "0  ...                 1               1             0           0   \n",
       "1  ...                 1               2             0           0   \n",
       "2  ...                 1               3             0           0   \n",
       "3  ...                 1               3             1           1   \n",
       "4  ...                 1              40             0           0   \n",
       "\n",
       "   ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  attack_cat  \\\n",
       "0                 0           1           1                0      Normal   \n",
       "1                 0           1           6                0      Normal   \n",
       "2                 0           2           6                0      Normal   \n",
       "3                 0           2           1                0      Normal   \n",
       "4                 0           2          39                0      Normal   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C5hh-CdxbjCZ",
    "outputId": "084d4fe8-9e4a-4671-ab72-af4f39e722e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train contamination  0.68\n",
      "test  contamination  0.55 \n",
      "\n",
      "Contamination is 0.68, which is greater than 0.5. Fixing...\n",
      "Contamination is now 0.32\n"
     ]
    }
   ],
   "source": [
    "# Contaminsation mean pollution (outliers) in data\n",
    "tmp = train.where(train['attack_cat'] == \"Normal\").dropna()\n",
    "contamination = round(1 - len(tmp)/len(train), 2)\n",
    "print(\"train contamination \", contamination)\n",
    "\n",
    "tmp = test.where(test['attack_cat'] == \"Normal\").dropna()\n",
    "print(\"test  contamination \", round(1 - len(tmp)/len(test),2),'\\n')\n",
    "\n",
    "if contamination > 0.5:\n",
    "    print(f'Contamination is {contamination}, which is greater than 0.5. Fixing...')\n",
    "    contamination = round(1-contamination, 2)\n",
    "    print(f'Contamination is now {contamination}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_tfrFURcVJ6X",
    "outputId": "ab9535db-7d1c-4dd2-8697-bd3c8d4bb517"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attack cat: {'Worms', 'Generic', 'Backdoor', 'Shellcode', 'Reconnaissance', 'Exploits', 'Fuzzers', 'Analysis', 'DoS', 'Normal'}\n",
      "\n",
      "Describing attack_type: \n",
      "min 0\n",
      "max 9\n",
      "mode 0    6\n",
      "dtype: int32 Which is, ['Normal']\n",
      "mode 0.3609225646458884 %\n"
     ]
    }
   ],
   "source": [
    "le1 = LabelEncoder()\n",
    "le = LabelEncoder()\n",
    "\n",
    "vector = combined_data['attack_cat']\n",
    "\n",
    "print(\"attack cat:\", set(list(vector))) # use print to make it print on single line \n",
    "\n",
    "combined_data['attack_cat'] = le1.fit_transform(vector)\n",
    "combined_data['proto'] = le.fit_transform(combined_data['proto'])\n",
    "combined_data['service'] = le.fit_transform(combined_data['service'])\n",
    "combined_data['state'] = le.fit_transform(combined_data['state'])\n",
    "\n",
    "vector = combined_data['attack_cat']\n",
    "print('\\nDescribing attack_type: ')\n",
    "print(\"min\", vector.min())\n",
    "print(\"max\", vector.max())\n",
    "print(\"mode\", vector.mode(), \"Which is,\", le1.inverse_transform(vector.mode()))\n",
    "print(\"mode\", len(np.where(vector.values==6)[0])/len(vector),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "id": "FdGigIypbQfd",
    "outputId": "e2b410cf-eee8-4070-ab7a-a7ae2da07083"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Analysis', 'Backdoor', 'DoS', 'Exploits', 'Fuzzers', 'Generic',\n",
       "       'Normal', 'Reconnaissance', 'Shellcode', 'Worms'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>sttl</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "      <th>attack_cat</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.121478</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>258</td>\n",
       "      <td>172</td>\n",
       "      <td>74.087490</td>\n",
       "      <td>252</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.649902</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>38</td>\n",
       "      <td>734</td>\n",
       "      <td>42014</td>\n",
       "      <td>78.473372</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.623129</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>364</td>\n",
       "      <td>13186</td>\n",
       "      <td>14.170161</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        dur  proto  service  state  spkts  dpkts  sbytes  dbytes       rate  \\\n",
       "0  0.121478    113        0      4      6      4     258     172  74.087490   \n",
       "1  0.649902    113        0      4     14     38     734   42014  78.473372   \n",
       "2  1.623129    113        0      4      8     16     364   13186  14.170161   \n",
       "\n",
       "   sttl  ...  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  ct_ftp_cmd  \\\n",
       "0   252  ...                 1               1             0           0   \n",
       "1    62  ...                 1               2             0           0   \n",
       "2    62  ...                 1               3             0           0   \n",
       "\n",
       "   ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  attack_cat  \\\n",
       "0                 0           1           1                0           6   \n",
       "1                 0           1           6                0           6   \n",
       "2                 0           2           6                0           6   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "\n",
       "[3 rows x 44 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le1.inverse_transform([0,1,2,3,4,5,6,7,8,9])\n",
    "combined_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "1bFqsTemVJ92"
   },
   "outputs": [],
   "source": [
    "lowSTD = list(combined_data.std().to_frame().nsmallest(6, columns=0).index)\n",
    "# this is stupid. suppose a feature has a 1.0 (spearman or pearson) correlation, OR conditional probability, when not 0.... That a very useful feature  \n",
    "\n",
    "lowCORR = list(combined_data.corr().abs().sort_values('attack_cat')['attack_cat'].nsmallest(3).index) # .where(lambda x: x < 0.005).dropna()\n",
    "# This might be stupid. A Deep MLP (feed forward neural net) may see patterns\n",
    "\n",
    "drop = set(lowCORR + lowSTD)\n",
    "# // drop = {'ackdat', 'ct_ftp_cmd', 'djit', 'is_ftp_login', 'is_sm_ips_ports', 'response_body_len', 'sjit', 'synack', 'tcprtt'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OMITTED: statistical feature removal\n",
    "\n",
    "# print(f'Before {combined_data.shape}')\n",
    "combined_data_reduced=combined_data # .drop(drop,axis=1)\n",
    "# print(f'After {combined_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Pjuk4i-aVAx7"
   },
   "outputs": [],
   "source": [
    "# # transform = list(combined_data_reduced.columns.values[4:])\n",
    "# transform.append('dur')\n",
    "# transform.remove('attack_cat')\n",
    "# # transform min-max norm \n",
    "# combined_data_reduced[transform] = combined_data_reduced[transform].apply(lambda x: (x - x.min()) / (x.max() - x.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "uRDvu_a8VA1q"
   },
   "outputs": [],
   "source": [
    "data_x = combined_data_reduced.drop(['attack_cat','label'], axis=1) # droped label\n",
    "\n",
    "if BINARY:\n",
    "    data_y = combined_data_reduced.loc[:, ['label']] \n",
    "else: \n",
    "    data_y = combined_data_reduced.loc[:, ['attack_cat']]\n",
    "# del combined_data # free mem\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_x, data_y, test_size=.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 1, 0, 4, 8, 7, 3, 2, 9, 5])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_y.iloc[:, 0].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "l53VPdZ0ZA95"
   },
   "outputs": [],
   "source": [
    "#combined_data_reduced.where(combined_data_reduced['label'] == 1.0).dropna().tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xjNm11s-fqvw",
    "outputId": "0facfb15-6352-47d9-e80a-22cfaa711652"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(206138, 42)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(206138, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(51535, 42)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(51535, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "y_train.shape\n",
    "X_test.shape # test is larger... good \n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gVO_4gmThrU-"
   },
   "source": [
    "# Benchmark before feature removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YZYIJ9d_VA57",
    "outputId": "51061509-b062-4e41-d888-03aa71538186"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.82746 for the RandomForestClassifier\n",
      "Acc: 0.82651 for the ExtraTreesClassifier\n",
      "[10:40:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Acc: 0.83539 for the XGBClassifier\n",
      "Acc: 0.64139 for the LGBMClassifier\n"
     ]
    }
   ],
   "source": [
    "RFC = RandomForestClassifier(n_estimators=150, random_state=42, n_jobs=-1)\n",
    "ETC = ExtraTreesClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "XGB = xgboost.XGBClassifier(n_estimators=75, n_jobs=-1)\n",
    "if BINARY:\n",
    "    GBM = lightgbm.LGBMClassifier(objective='binary', n_estimators= 500, n_jobs=-1)\n",
    "else:\n",
    "    GBM = lightgbm.LGBMClassifier(objective='multiclass', n_estimators= 500, n_jobs=-1) # multiclass\n",
    "list_of_CLFs_names, ranking = [], []\n",
    "list_of_CLFs = [RFC, ETC, XGB, GBM]\n",
    "\n",
    "for clf in list_of_CLFs:\n",
    "    _ = clf.fit(X_train,y_train)\n",
    "    pred = clf.score(X_test,y_test)\n",
    "    name = str(type(clf)).split(\".\")[-1][:-2]\n",
    "    print(\"Acc: %0.5f for the %s\" % (pred, name))\n",
    "\n",
    "    ranking.append(pred)\n",
    "    list_of_CLFs_names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UJTr88Kge5bs",
    "outputId": "98f069ae-ff77-41a6-f91d-dbbe1ac0569e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.82348 for the EnsembleVoteClassifier\n"
     ]
    }
   ],
   "source": [
    "eclf = EnsembleVoteClassifier(clfs=list_of_CLFs, voting='soft', fit_base_estimators=False)\n",
    "_ = eclf.fit(X_train, y_train)\n",
    "pred = eclf.score(X_test, y_test)\n",
    "print(\"Acc: %0.5f for the %s\" % (pred, str(type(eclf)).split(\".\")[-1][:-2]))\n",
    "\n",
    "\n",
    "pred = eclf.predict(X_test)\n",
    "probas = eclf.predict_proba(X_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VoMwRzRn5uy0",
    "outputId": "f7ec7efc-afc6-44c0-981d-ab9be1ac4683"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.82406 for the CatBoostClassifier\n"
     ]
    }
   ],
   "source": [
    "import catboost\n",
    "\n",
    "# CBC = catboost.CatBoostClassifier(iterations=3000, eval_metric='AUC', task_type=\"GPU\", devices='0:1', random_seed=42, verbose=False) #  use_best_model=True\n",
    "CBC = catboost.CatBoostClassifier(eval_metric='AUC', random_seed=42, verbose=False)\n",
    "\n",
    "_ = CBC.fit(X_train,y_train, eval_set=(X_test, y_test))\n",
    "pred = CBC.score(X_test,y_test)\n",
    "name = str(type(CBC)).split(\".\")[-1][:-2]\n",
    "print(\"Acc: %0.5f for the %s\" % (pred, name))\n",
    "list_of_CLFs.append(CBC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FhkbYaMy7ElM",
    "outputId": "47e75af9-4238-44a8-9b85-90658f721b5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.82748 for the EnsembleVoteClassifier\n"
     ]
    }
   ],
   "source": [
    "eclf = EnsembleVoteClassifier(clfs=list_of_CLFs, voting='soft', fit_base_estimators=False)\n",
    "_ = eclf.fit(X_train, y_train)\n",
    "pred = eclf.score(X_test, y_test)\n",
    "print(\"Acc: %0.5f for the %s\" % (pred, str(type(eclf)).split(\".\")[-1][:-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "MU1Lvj7fVA9S"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(206138, 42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.decomposition import PCA, TruncatedSVD, PCA\n",
    "from sklearn.svm import LinearSVC\n",
    "n = 10 \n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNu2XDAIjaQs"
   },
   "source": [
    "### Try RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "5UJPOp7yVBA9",
    "outputId": "e87cfbb9-7580-407a-cc28-0abe60002b27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new shape (206138, 10)\n",
      "Acc: 0.82375 for the RandomForestClassifier\n",
      "Acc: 0.81873 for the ExtraTreesClassifier\n",
      "[10:52:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Acc: 0.82439 for the XGBClassifier\n",
      "Acc: 0.70769 for the LGBMClassifier\n",
      "Acc: 0.82154 for the CatBoostClassifier\n",
      "[10:57:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Acc: 0.81756 for the EnsembleVoteClassifier\n"
     ]
    }
   ],
   "source": [
    "rfe = RFE(DecisionTreeClassifier(), n).fit(X_train, y_train)\n",
    "\n",
    "desiredIndices = np.where(rfe.support_==True)[0]\n",
    "whitelist = X_train.columns.values[desiredIndices]\n",
    "X_train_RFE, X_test_RFE = X_train[whitelist], X_test[whitelist]\n",
    "\n",
    "print('new shape', X_train_RFE.shape) \n",
    "\n",
    "for clf in list_of_CLFs:\n",
    "    _ = clf.fit(X_train_RFE,y_train)\n",
    "    pred = clf.score(X_test_RFE,y_test)\n",
    "    name = str(type(clf)).split(\".\")[-1][:-2]\n",
    "    print(\"Acc: %0.5f for the %s\" % (pred, name))\n",
    "\n",
    "    ranking.append(pred)\n",
    "    list_of_CLFs_names.append(name)\n",
    "\n",
    "\n",
    "eclf = EnsembleVoteClassifier(clfs=list_of_CLFs, voting='soft')\n",
    "_ = eclf.fit(X_train_RFE, y_train)\n",
    "pred = eclf.score(X_test_RFE, y_test)\n",
    "print(\"Acc: %0.5f for the %s\" % (pred, str(type(eclf)).split(\".\")[-1][:-2]))\n",
    "\n",
    "\n",
    "pred = eclf.predict(X_test_RFE)\n",
    "probas = eclf.predict_proba(X_test_RFE)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEl8uH1njcvP"
   },
   "source": [
    "### Try SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "id": "DL6SblkRVBEs",
    "outputId": "cf15430a-e8b9-4d78-9b81-5b78f9c351ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.75089 for the RandomForestClassifier\n",
      "Acc: 0.74868 for the ExtraTreesClassifier\n",
      "[11:02:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Acc: 0.74109 for the XGBClassifier\n",
      "Acc: 0.61019 for the LGBMClassifier\n",
      "Acc: 0.73938 for the CatBoostClassifier\n",
      "[11:08:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Acc: 0.74800 for the EnsembleVoteClassifier\n"
     ]
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=n).fit(X_train)\n",
    "X_train_svd, X_test_svd = svd.transform(X_train), svd.transform(X_test)\n",
    "\n",
    "for clf in list_of_CLFs:\n",
    "    _ = clf.fit(X_train_svd, y_train)\n",
    "    pred = clf.score(X_test_svd, y_test)\n",
    "    name = str(type(clf)).split(\".\")[-1][:-2]\n",
    "    print(\"Acc: %0.5f for the %s\" % (pred, name))\n",
    "\n",
    "    ranking.append(pred)\n",
    "    list_of_CLFs_names.append(name)\n",
    "\n",
    "eclf = EnsembleVoteClassifier(clfs=list_of_CLFs, voting='soft')\n",
    "_ = eclf.fit(X_train_svd, y_train)\n",
    "pred = eclf.score(X_test_svd, y_test)\n",
    "print(\"Acc: %0.5f for the %s\" % (pred, str(type(eclf)).split(\".\")[-1][:-2]))\n",
    "\n",
    "\n",
    "pred = eclf.predict(X_test_svd)\n",
    "probas = eclf.predict_proba(X_test_svd)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AgKg-9lehlHl"
   },
   "source": [
    "# Benchmark after additional feature removal [Binary Classification]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4TKXI3uhe9Iz"
   },
   "source": [
    " **predicting *label*:** \n",
    "```\n",
    "RFE only \n",
    "Acc: 0.9259010116 [DecisionTreeClassifier]\n",
    "Acc: 0.9258389175 [RandomForestClassifier]\n",
    "Acc: 0.9255957155 [ExtraTreesClassifier]\n",
    "Acc: 0.9259010116 [Ensemble]\n",
    "number of features 20\n",
    "---------------\n",
    "Acc: 0.9386820522\n",
    "number of features 10\n",
    "[ pipeing to SVD 9 dimentions yeilds:  Acc: 0.9221753642 [Ensemble] ; piping to PCA will yeild .921] \n",
    "```\n",
    "```\n",
    "(64418, 20)\n",
    "* Acc: 0.9283589040 [DecisionTreeClassifier]\n",
    "* Acc: 0.9278052314 [RandomForestClassifier]\n",
    "* Acc: 0.9286848982 [ExtraTreesClassifier]\n",
    "* Acc: 0.9278000569 [Ensemble]\n",
    "```\n",
    "```\n",
    "(64418, 10)\n",
    "Acc: 0.9141341751 [DecisionTreeClassifier]\n",
    "Acc: 0.9145119143 [RandomForestClassifier]\n",
    "Acc: 0.9141290005 [ExtraTreesClassifier]\n",
    "Acc: 0.9135028848 [Ensemble]\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JApW6PtyluMN"
   },
   "source": [
    "# Lets' try another way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "X40zFLvrjReM"
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.linear_model import RidgeClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# seed = 1075\n",
    "# np.random.seed(seed)\n",
    "# # Create classifiers\n",
    "# rf = RandomForestClassifier()\n",
    "# et = ExtraTreesClassifier()\n",
    "# knn = KNeighborsClassifier()\n",
    "# svc = SVC()\n",
    "# rg = RidgeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Qe4Y-NL0jRhs"
   },
   "outputs": [],
   "source": [
    "# clf_array = [rf, et, knn, svc, rg]\n",
    "# for clf in clf_array:\n",
    "#     vanilla_scores = cross_val_score(clf, X_train_RFE, y_train, cv=3, n_jobs=-1)\n",
    "#     bagging_clf = BaggingClassifier(clf, \n",
    "#        max_samples=0.4, max_features=10, random_state=seed)\n",
    "#     bagging_scores = cross_val_score(bagging_clf, X_test, y_test, cv=3, \n",
    "#        n_jobs=-1)\n",
    "    \n",
    "#     print(\"Mean of: {1:.3f}, std: (+/-) {2:.3f} [{0}]\".format(clf.__class__.__name__,vanilla_scores.mean(), vanilla_scores.std()))\n",
    "#     print(\"Mean of: {1:.3f}, std: (+/-) {2:.3f} [Bagging {0}]\\n\".format(clf.__class__.__name__,bagging_scores.mean(), bagging_scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1pgtJb9jRk_"
   },
   "source": [
    "# Onto Deep Learning \n",
    "> I ran SVD/PCA to reduce variance since my goal to \"get the best deep learning results possible\" \n",
    "\n",
    "^ I wrote that 18 months. not sure why that really \"matters\". now I prefer to given `full` data to my ANNs, and let them `learn` to ignore useless features\n",
    "\n",
    "#### Now that I try this, I get worse results, I must have done somthing breaking. This is not my goal, `UNSW-NB15_Unsupervised` is. So, ill leave this broken.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6jdE--4z6ff"
   },
   "source": [
    "```\n",
    "Notes: \n",
    "\n",
    "sigmoid for binary \n",
    "\n",
    "Softmax = non-binary \n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "b_jUtItsravz",
    "outputId": "3eb79c75-782f-4eaa-e8e0-f5a8e9d59e1e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X_train#_RFE\n",
    "X_t = X_test#_RFE\n",
    "\n",
    "\n",
    "dim = X.shape[1]\n",
    "dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "04JL4rPm5xKc"
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# mms = MinMaxScaler()\n",
    "# X_train_svd = mms.fit_transform(X_train_svd)\n",
    "# X_test_svd = mms.transform(X_test_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "ux-s4sn0jRvY"
   },
   "outputs": [],
   "source": [
    "# classifier = Sequential()\n",
    "# #First Hidden Layer\n",
    "# classifier.add(Dense(42, activation='relu', input_dim=dim))\n",
    "\n",
    "# classifier.add(Dense(64, activation='relu'))\n",
    "# classifier.add(Dropout(0.07))\n",
    "# classifier.add(Dense(42, activation='relu' ))\n",
    "# classifier.add(Dropout(0.07))\n",
    "# classifier.add(Dense(25, activation='relu'))\n",
    "\n",
    "# classifier.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "7bqvWXJjnPGn",
    "outputId": "25c1d3ff-a064-4abb-f27b-5aeed83a9f17"
   },
   "outputs": [],
   "source": [
    "# history = classifier.fit(X,y_train, batch_size=64, epochs=5, validation_data=(X_t,y_test)).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "id": "STqFbIZOnPNn",
    "outputId": "c1a85919-8ef6-4370-9d75-1c7c6cb5fd8c"
   },
   "outputs": [],
   "source": [
    "# eval_model=classifier.evaluate(X, y_train)\n",
    "# print(eval_model)\n",
    "\n",
    "# eval_model=classifier.evaluate(X_t, y_test)\n",
    "# print(eval_model)\n",
    "\n",
    "\n",
    "# predictions=classifier.predict(X_t)\n",
    "# predictions =(predictions>0.80)\n",
    "\n",
    "# mse = np.mean(np.power(X_t - predictions, 2), axis=1)\n",
    "# error_df = pd.DataFrame({'reconstruction_error': mse,'true_class': y_test.values.reshape(1,-1)[0]})\n",
    "# error_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "40tdgoNHnMfa",
    "outputId": "50e12479-6ad2-49fe-b345-b2b126e75e3b"
   },
   "outputs": [],
   "source": [
    "# plt.plot(history['loss'])\n",
    "# plt.plot(history['val_loss'])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "w9Jq4HEQnMjK",
    "outputId": "f7c1277f-b1d4-4731-a07b-f11a6a3b4dac"
   },
   "outputs": [],
   "source": [
    "# fpr, tpr, thresholds = roc_curve(error_df.true_class, error_df.reconstruction_error,pos_label=1)\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "\n",
    "\n",
    "# plt.title('Receiver Operating Characteristic')\n",
    "# plt.plot(fpr, tpr, label='AUC = %0.4f'% roc_auc)\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.plot([0,1],[0,1],'r--')\n",
    "# plt.xlim([-0.001, 1])\n",
    "# plt.ylim([0, 1.001])\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "HWJk5_AlnMnM",
    "outputId": "f3fb9e3a-d9c2-49eb-efb3-2039fecd15af"
   },
   "outputs": [],
   "source": [
    "# precision, recall, th = precision_recall_curve(error_df.true_class, error_df.reconstruction_error,pos_label=1)\n",
    "# plt.plot(recall, precision, 'b', label='Precision-Recall curve')\n",
    "# plt.title('Recall vs Precision')\n",
    "# plt.xlabel('Recall')\n",
    "# plt.ylabel('Precision')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "CjRc41fsnMr6"
   },
   "outputs": [],
   "source": [
    "## MLP with Pytorch \n",
    "\n",
    "# This code has only been run on `UNSW_NB15 - Torch MLP and autoEncoder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "X05LsfcUjRyh"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "\n",
    "input_size = 10\n",
    "hidden_size = 64 \n",
    "hidden_size_2 = 64\n",
    "num_classes = 10\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Fully connected neural network with one hidden layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.input_size = input_size # ?? \n",
    "        self.l1 = nn.Linear(input_size, hidden_size) \n",
    "        self.l2 = nn.Linear(hidden_size, hidden_size_2)  \n",
    "        self.l3 = nn.Linear(hidden_size_2, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.elu = nn.ELU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.l3(out)\n",
    "        # no activation and no softmax at the end\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "Po7VpfirjR2L"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_RFE_vals' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-556e56ef78fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mn_total_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train_RFE_vals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mX_train_RFE_vals\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mX_train_RFE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_RFE_vals' is not defined"
     ]
    }
   ],
   "source": [
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss() # This criterion combines nn.LogSoftmax() and nn.NLLLoss() in one single class.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "# Train the model\n",
    "n_total_steps = X_train_RFE_vals.shape[0]\n",
    "\n",
    "X_train_RFE_vals= X_train_RFE.values\n",
    "y_train_vals = y_train.values\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # for i in range(len(X_train_RFE_vals)//100 + 1): #, batch_size\n",
    "    for i in range(0, X_train_RFE_vals.shape[0], batch_size):\n",
    "\n",
    "        x = torch.as_tensor(X_train_RFE_vals[i:i+batch_size], dtype=torch.float).to(device)\n",
    "        y = torch.as_tensor(y_train_vals[i:i+batch_size], dtype=torch.long).to(device)\n",
    "\n",
    "        # x.type()\n",
    "        # y.type()\n",
    "\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y.flatten())\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "#     if (epoch+1) % 10 == 0:\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}] | Step [{i+1}/{n_total_steps}] | Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r5SPcmAFjR5l"
   },
   "outputs": [],
   "source": [
    "## Broken code. See other notebook.\n",
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients\n",
    "# X_test_RFE_vals= X_test_RFE.values\n",
    "# y_test_vals = y_test.values\n",
    "# with torch.no_grad():\n",
    "#     n_correct = 0\n",
    "#     n_samples = 0 \n",
    "#     # for i in range(len(X_train_RFE_vals)//100 + 1):   \n",
    "#     for i in range(0, X_test_RFE_vals.shape[0], 1):\n",
    "#         x = torch.as_tensor(X_test_RFE_vals[i:i+batch_size], dtype=torch.float).to(device)\n",
    "#         y = torch.as_tensor(y_test_vals[i:i+batch_size], dtype=torch.long).to(device)\n",
    "        \n",
    "#         outputs = model(x)\n",
    "#         if len(outputs.data) > 0:\n",
    "#           # max returns (value ,index)\n",
    "#           _, predicted = torch.max(outputs.data, dim=1)\n",
    "#           n_samples += y.size(0)\n",
    "#           n_correct += (predicted == y).sum().item()\n",
    "#         else:\n",
    "#           print(\"what???\")\n",
    "#           print(x, outputs.data)\n",
    "#     acc = 100.0 * n_correct / (n_samples+1)\n",
    "#     print(f'Accuracy of the network: {acc} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XpSg_uGZjR9J"
   },
   "source": [
    "> Accuracy of the network: 79.64%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9HMfAuoOjSAq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o3yKHghIjSEV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ixQ7uR00jSIB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4OHfbx1qjSLS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "twvrr6d5jSOq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I8gsbiYtjSRk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1T_uPrDSjRop"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jmvwsp-KnNWi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gJY4PEQhnNb5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PkbExAc-nNfp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T2aaz0iLnNja"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v30s7FidnNm-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ARG5tDbjnNqa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "74QP1VY6nNth"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mohA8IeSnNw7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a-Jf6wmTnN0B"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LVGSOxgunN3S"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tkcSDGFhnN6H"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DMKSBLJknN8i"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "UNSW-NB15",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
