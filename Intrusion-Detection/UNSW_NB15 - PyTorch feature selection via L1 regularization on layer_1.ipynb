{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "UNSW_NB15 - PyTorch feature selection via L1 regularization on layer_1 ",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alik604/cyber-security/blob/master/Intrusion-Detection/UNSW_NB15%20-%20PyTorch%20feature%20selection%20via%20L1%20regularization%20on%20layer_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl-cPhNxn6QU"
      },
      "source": [
        " ## References \n",
        "\n",
        " *note that this is binary classification*\n",
        " \n",
        " MLP with pytorch at end\n",
        " \n",
        " * Data source: https://www.unsw.adfa.edu.au/unsw-canberra-cyber/cybersecurity/ADFA-NB15-Datasets/\n",
        " * Sample/starter code: https://github.com/Nir-J/ML-Projects/blob/master/UNSW-Network_Packet_Classification/unsw.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lx1Zh6UUU-ov"
      },
      "source": [
        "%config IPCompleter.greedy=True\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib as matplot\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from keras import Sequential\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import *\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import regularizers\n",
        "\n",
        "from sklearn.metrics import *\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, VotingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder,normalize\n",
        "\n",
        "\n",
        "import xgboost, lightgbm\n",
        "from mlxtend.classifier import EnsembleVoteClassifier"
      ],
      "execution_count": 339,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2Kvca3apvAc"
      },
      "source": [
        "# Preprocessing (transformation/scaling) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjw9JrARVJ23"
      },
      "source": [
        "train = pd.read_csv('https://raw.githubusercontent.com/Nir-J/ML-Projects/master/UNSW-Network_Packet_Classification/UNSW_NB15_training-set.csv')\n",
        "test = pd.read_csv('https://raw.githubusercontent.com/Nir-J/ML-Projects/master/UNSW-Network_Packet_Classification/UNSW_NB15_testing-set.csv')\n",
        "combined_data = pd.concat([train, test]).drop(['id'],axis=1)"
      ],
      "execution_count": 340,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5hh-CdxbjCZ",
        "outputId": "ea3347a3-bb7f-488d-9afb-951c5df4eb41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Contaminsation mean pollution (outliers) in data\n",
        "tmp = train.where(train['attack_cat'] == \"Normal\").dropna()\n",
        "contamination = round(1 - len(tmp)/len(train), 2)\n",
        "print(\"train contamination \", contamination)\n",
        "\n",
        "tmp = test.where(test['attack_cat'] == \"Normal\").dropna()\n",
        "print(\"test  contamination \", round(1 - len(tmp)/len(test),2),'\\n')\n",
        "\n",
        "if contamination > 0.5:\n",
        "    print(f'contamination is {contamination}, which is greater than 0.5. Fixing...')\n",
        "    contamination = round(1-contamination,2)\n",
        "    print(f'contamination is now {contamination}')"
      ],
      "execution_count": 341,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train contamination  0.68\n",
            "test  contamination  0.55 \n",
            "\n",
            "contamination is 0.68, which is greater than 0.5. Fixing...\n",
            "contamination is now 0.32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tfrFURcVJ6X",
        "outputId": "bfe09d3e-fb08-47e6-9ee1-0d4f2703df35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "le1 = LabelEncoder()\n",
        "le = LabelEncoder()\n",
        "\n",
        "vector = combined_data['attack_cat']\n",
        "\n",
        "print(\"attack cat:\", set(list(vector))) # use print to make it print on single line \n",
        "\n",
        "combined_data['attack_cat'] = le1.fit_transform(vector)\n",
        "combined_data['proto'] = le.fit_transform(combined_data['proto'])\n",
        "combined_data['service'] = le.fit_transform(combined_data['service'])\n",
        "combined_data['state'] = le.fit_transform(combined_data['state'])\n",
        "\n",
        "vector = combined_data['attack_cat']\n",
        "print('\\nDescribing attack_type: ')\n",
        "print(\"min\", vector.min())\n",
        "print(\"max\", vector.max())\n",
        "print(\"mode\",vector.mode(), \"Which is,\", le1.inverse_transform(vector.mode()))\n",
        "print(\"mode\", len(np.where(vector.values==6)[0])/len(vector),\"%\")"
      ],
      "execution_count": 342,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "attack cat: {'Fuzzers', 'DoS', 'Analysis', 'Generic', 'Normal', 'Backdoor', 'Reconnaissance', 'Exploits', 'Worms', 'Shellcode'}\n",
            "\n",
            "Describing attack_type: \n",
            "min 0\n",
            "max 9\n",
            "mode 0    6\n",
            "dtype: int64 Which is, ['Normal']\n",
            "mode 0.3609225646458884 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdGigIypbQfd",
        "outputId": "12c71b0c-a8e2-426a-a154-8a04c35ff867",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "le1.inverse_transform([0,1,2,3,4,5,6,7,8,9])\n",
        "combined_data.head(3)"
      ],
      "execution_count": 343,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Analysis', 'Backdoor', 'DoS', 'Exploits', 'Fuzzers', 'Generic',\n",
              "       'Normal', 'Reconnaissance', 'Shellcode', 'Worms'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 343
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dur</th>\n",
              "      <th>proto</th>\n",
              "      <th>service</th>\n",
              "      <th>state</th>\n",
              "      <th>spkts</th>\n",
              "      <th>dpkts</th>\n",
              "      <th>sbytes</th>\n",
              "      <th>dbytes</th>\n",
              "      <th>rate</th>\n",
              "      <th>sttl</th>\n",
              "      <th>dttl</th>\n",
              "      <th>sload</th>\n",
              "      <th>dload</th>\n",
              "      <th>sloss</th>\n",
              "      <th>dloss</th>\n",
              "      <th>sinpkt</th>\n",
              "      <th>dinpkt</th>\n",
              "      <th>sjit</th>\n",
              "      <th>djit</th>\n",
              "      <th>swin</th>\n",
              "      <th>stcpb</th>\n",
              "      <th>dtcpb</th>\n",
              "      <th>dwin</th>\n",
              "      <th>tcprtt</th>\n",
              "      <th>synack</th>\n",
              "      <th>ackdat</th>\n",
              "      <th>smean</th>\n",
              "      <th>dmean</th>\n",
              "      <th>trans_depth</th>\n",
              "      <th>response_body_len</th>\n",
              "      <th>ct_srv_src</th>\n",
              "      <th>ct_state_ttl</th>\n",
              "      <th>ct_dst_ltm</th>\n",
              "      <th>ct_src_dport_ltm</th>\n",
              "      <th>ct_dst_sport_ltm</th>\n",
              "      <th>ct_dst_src_ltm</th>\n",
              "      <th>is_ftp_login</th>\n",
              "      <th>ct_ftp_cmd</th>\n",
              "      <th>ct_flw_http_mthd</th>\n",
              "      <th>ct_src_ltm</th>\n",
              "      <th>ct_srv_dst</th>\n",
              "      <th>is_sm_ips_ports</th>\n",
              "      <th>attack_cat</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.121478</td>\n",
              "      <td>113</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>258</td>\n",
              "      <td>172</td>\n",
              "      <td>74.087490</td>\n",
              "      <td>252</td>\n",
              "      <td>254</td>\n",
              "      <td>14158.942380</td>\n",
              "      <td>8495.365234</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24.295600</td>\n",
              "      <td>8.375000</td>\n",
              "      <td>30.177547</td>\n",
              "      <td>11.830604</td>\n",
              "      <td>255</td>\n",
              "      <td>621772692</td>\n",
              "      <td>2202533631</td>\n",
              "      <td>255</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>43</td>\n",
              "      <td>43</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.649902</td>\n",
              "      <td>113</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>38</td>\n",
              "      <td>734</td>\n",
              "      <td>42014</td>\n",
              "      <td>78.473372</td>\n",
              "      <td>62</td>\n",
              "      <td>252</td>\n",
              "      <td>8395.112305</td>\n",
              "      <td>503571.312500</td>\n",
              "      <td>2</td>\n",
              "      <td>17</td>\n",
              "      <td>49.915000</td>\n",
              "      <td>15.432865</td>\n",
              "      <td>61.426934</td>\n",
              "      <td>1387.778330</td>\n",
              "      <td>255</td>\n",
              "      <td>1417884146</td>\n",
              "      <td>3077387971</td>\n",
              "      <td>255</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>52</td>\n",
              "      <td>1106</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>43</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.623129</td>\n",
              "      <td>113</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>16</td>\n",
              "      <td>364</td>\n",
              "      <td>13186</td>\n",
              "      <td>14.170161</td>\n",
              "      <td>62</td>\n",
              "      <td>252</td>\n",
              "      <td>1572.271851</td>\n",
              "      <td>60929.230470</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>231.875571</td>\n",
              "      <td>102.737203</td>\n",
              "      <td>17179.586860</td>\n",
              "      <td>11420.926230</td>\n",
              "      <td>255</td>\n",
              "      <td>2116150707</td>\n",
              "      <td>2963114973</td>\n",
              "      <td>255</td>\n",
              "      <td>0.111897</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>0.050439</td>\n",
              "      <td>46</td>\n",
              "      <td>824</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        dur  proto  service  ...  is_sm_ips_ports  attack_cat  label\n",
              "0  0.121478    113        0  ...                0           6      0\n",
              "1  0.649902    113        0  ...                0           6      0\n",
              "2  1.623129    113        0  ...                0           6      0\n",
              "\n",
              "[3 rows x 44 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 343
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bFqsTemVJ92"
      },
      "source": [
        "## OMITTED: For statistical feature removal\n",
        "\n",
        "lowSTD = list(combined_data.std().to_frame().nsmallest(6, columns=0).index)\n",
        "# this is stupid. suppose a feature has a 1.0 (spearman or pearson) correlation, OR conditional probability, when not 0.... That a very useful feature  \n",
        "\n",
        "lowCORR = list(combined_data.corr().abs().sort_values('attack_cat')['attack_cat'].nsmallest(3).index) # .where(lambda x: x < 0.005).dropna()\n",
        "# This might be stupid. A Deep MLP (feed forward neural net) may see patterns\n",
        "\n",
        "drop = set( lowCORR + lowSTD)\n",
        "drop = {'ackdat', 'ct_ftp_cmd', 'djit', 'is_ftp_login', 'is_sm_ips_ports', 'response_body_len', 'sjit', 'synack', 'tcprtt'}\n",
        "# print(f'Before {combined_data.shape}')\n",
        "combined_data_reduced=combined_data # .drop(drop,axis=1)\n",
        "# print(f'After {combined_data.shape}')"
      ],
      "execution_count": 344,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pjuk4i-aVAx7"
      },
      "source": [
        "# # transform = list(combined_data_reduced.columns.values[4:])\n",
        "# transform.append('dur')\n",
        "# transform.remove('attack_cat')\n",
        "# # transform min-max norm \n",
        "# combined_data_reduced[transform] = combined_data_reduced[transform].apply(lambda x: (x - x.min()) / (x.max() - x.min()))"
      ],
      "execution_count": 345,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRDvu_a8VA1q"
      },
      "source": [
        "data_x = combined_data_reduced.drop(['attack_cat','label'], axis=1) # droped label\n",
        "data_y = combined_data_reduced.loc[:,['label']]\n",
        "# del combined_data # free mem\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_x, data_y, test_size=.20, random_state=42) # TODO"
      ],
      "execution_count": 346,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l53VPdZ0ZA95"
      },
      "source": [
        "#combined_data_reduced.where(combined_data_reduced['label'] == 1.0).dropna().tail(20)"
      ],
      "execution_count": 347,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjNm11s-fqvw",
        "outputId": "6d5a85e7-eb40-4e52-ede4-9506f34cced4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape\n",
        "y_train.shape\n",
        "X_test.shape # test is larger... good \n",
        "y_test.shape"
      ],
      "execution_count": 348,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(206138, 42)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 348
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(206138, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 348
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(51535, 42)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 348
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(51535, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 348
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVO_4gmThrU-"
      },
      "source": [
        "# Benchmark before feature removal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZYIJ9d_VA57",
        "outputId": "6628ea42-e399-4de9-f510-197b67cbdae1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "DTC = DecisionTreeClassifier()\n",
        "RFC = RandomForestClassifier(n_estimators=150, random_state=42, n_jobs=-1)\n",
        "ETC = ExtraTreesClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
        "XGB = xgboost.XGBClassifier(n_estimators=150, n_jobs=-1)\n",
        "GBM = lightgbm.LGBMClassifier(objective='binary', n_estimators= 500) # multiclass\n",
        "\n",
        "list_of_CLFs_names = []\n",
        "list_of_CLFs = [DTC, RFC, ETC, XGB, GBM]\n",
        "ranking = []\n",
        "\n",
        "for clf in list_of_CLFs:\n",
        "    _ = clf.fit(X_train, y_train)\n",
        "    pred = clf.score(X_test, y_test)\n",
        "    name = str(type(clf)).split(\".\")[-1][:-2]\n",
        "    print(\"Acc: %0.5f for the %s\" % (pred, name))\n",
        "\n",
        "    ranking.append(pred)\n",
        "    list_of_CLFs_names.append(name)"
      ],
      "execution_count": 349,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acc: 0.93752 for the DecisionTreeClassifier\n",
            "Acc: 0.95240 for the RandomForestClassifier\n",
            "Acc: 0.95133 for the ExtraTreesClassifier\n",
            "Acc: 0.93653 for the XGBClassifier\n",
            "Acc: 0.95269 for the LGBMClassifier\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJTr88Kge5bs",
        "outputId": "1870c805-26bc-49ba-ec54-ba59f075c9e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "eclf = EnsembleVoteClassifier(clfs=list_of_CLFs, refit=False, voting='soft')\n",
        "_ = eclf.fit(X_train, y_train)\n",
        "pred = eclf.score(X_test, y_test)\n",
        "print(\"Acc: %0.5f for the %s\" % (pred, str(type(eclf)).split(\".\")[-1][:-2]))\n",
        "\n",
        "\n",
        "pred = eclf.predict(X_test)\n",
        "probas = eclf.predict_proba(X_test)"
      ],
      "execution_count": 350,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acc: 0.95077 for the EnsembleVoteClassifier\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU1Lvj7fVA9S"
      },
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.decomposition import PCA, TruncatedSVD, PCA\n",
        "from sklearn.svm import LinearSVC\n",
        "n = 10 "
      ],
      "execution_count": 351,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNu2XDAIjaQs"
      },
      "source": [
        "### Try RFE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UJPOp7yVBA9",
        "outputId": "ea02343d-37cf-4827-b7e8-b32a3e2caaf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "rfe = RFE(DecisionTreeClassifier(), n).fit(X_train, y_train)\n",
        "\n",
        "desiredIndices = np.where(rfe.support_==True)[0]\n",
        "whitelist = X_train.columns.values[desiredIndices]\n",
        "X_train_RFE, X_test_RFE = X_train[whitelist], X_test[whitelist]\n",
        "\n",
        "print('new shape', X_train_RFE.shape) \n",
        "\n",
        "for clf in list_of_CLFs:\n",
        "    _ = clf.fit(X_train_RFE,y_train)\n",
        "    pred = clf.score(X_test_RFE,y_test)\n",
        "    name = str(type(clf)).split(\".\")[-1][:-2]\n",
        "    print(\"Acc: %0.5f for the %s\" % (pred, name))\n",
        "\n",
        "    ranking.append(pred)\n",
        "    list_of_CLFs_names.append(name)\n",
        "\n",
        "\n",
        "eclf = EnsembleVoteClassifier(clfs=list_of_CLFs, refit=False, voting='soft')\n",
        "_ = eclf.fit(X_train_RFE, y_train)\n",
        "pred = eclf.score(X_test_RFE, y_test)\n",
        "print(\"Acc: %0.5f for the %s\" % (pred, str(type(eclf)).split(\".\")[-1][:-2]))\n",
        "\n",
        "\n",
        "pred = eclf.predict(X_test_RFE)\n",
        "probas = eclf.predict_proba(X_test_RFE)"
      ],
      "execution_count": 352,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "new shape (206138, 10)\n",
            "Acc: 0.93705 for the DecisionTreeClassifier\n",
            "Acc: 0.95027 for the RandomForestClassifier\n",
            "Acc: 0.94846 for the ExtraTreesClassifier\n",
            "Acc: 0.93379 for the XGBClassifier\n",
            "Acc: 0.94804 for the LGBMClassifier\n",
            "Acc: 0.94902 for the EnsembleVoteClassifier\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEl8uH1njcvP"
      },
      "source": [
        "### Try SVD and PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DL6SblkRVBEs",
        "outputId": "3ad71536-fddc-4f92-8784-f3d708681ceb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "svd = TruncatedSVD(n_components=n).fit(X_train)\n",
        "X_train_svd, X_test_svd = svd.transform(X_train), svd.transform(X_test)\n",
        "\n",
        "for clf in list_of_CLFs:\n",
        "    _ = clf.fit(X_train_svd, y_train)\n",
        "    pred = clf.score(X_test_svd, y_test)\n",
        "    name = str(type(clf)).split(\".\")[-1][:-2]\n",
        "    print(\"Acc: %0.5f for the %s\" % (pred, name))\n",
        "\n",
        "    ranking.append(pred)\n",
        "    list_of_CLFs_names.append(name)\n",
        "\n",
        "eclf = EnsembleVoteClassifier(clfs=list_of_CLFs, refit=False, voting='soft')\n",
        "_ = eclf.fit(X_train_svd, y_train)\n",
        "pred = eclf.score(X_test_svd, y_test)\n",
        "print(\"Acc: %0.5f for the %s\" % (pred, str(type(eclf)).split(\".\")[-1][:-2]))\n",
        "\n",
        "\n",
        "pred = eclf.predict(X_test_svd)\n",
        "probas = eclf.predict_proba(X_test_svd)"
      ],
      "execution_count": 353,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acc: 0.87987 for the DecisionTreeClassifier\n",
            "Acc: 0.89908 for the RandomForestClassifier\n",
            "Acc: 0.89821 for the ExtraTreesClassifier\n",
            "Acc: 0.87024 for the XGBClassifier\n",
            "Acc: 0.88848 for the LGBMClassifier\n",
            "Acc: 0.89512 for the EnsembleVoteClassifier\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WT6trUnzJPk8",
        "outputId": "b426c234-279b-4765-a5ab-77ce5cbbd78b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "pca = PCA(n_components=n).fit(X_train)\n",
        "X_train_pca, X_test_pca = pca.transform(X_train), pca.transform(X_test)\n",
        "\n",
        "for clf in list_of_CLFs:\n",
        "    _ = clf.fit(X_train_pca, y_train)\n",
        "    pred = clf.score(X_test_pca, y_test)\n",
        "    name = str(type(clf)).split(\".\")[-1][:-2]\n",
        "    print(\"Acc: %0.5f for the %s\" % (pred, name))\n",
        "\n",
        "    ranking.append(pred)\n",
        "    list_of_CLFs_names.append(name)\n",
        "\n",
        "eclf = EnsembleVoteClassifier(clfs=list_of_CLFs, refit=False, voting='soft')\n",
        "_ = eclf.fit(X_train_pca, y_train)\n",
        "pred = eclf.score(X_test_pca, y_test)\n",
        "print(\"Acc: %0.5f for the %s\" % (pred, str(type(eclf)).split(\".\")[-1][:-2]))\n",
        "\n",
        "\n",
        "pred = eclf.predict(X_test_pca)\n",
        "probas = eclf.predict_proba(X_test_pca)"
      ],
      "execution_count": 354,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acc: 0.87896 for the DecisionTreeClassifier\n",
            "Acc: 0.89388 for the RandomForestClassifier\n",
            "Acc: 0.88905 for the ExtraTreesClassifier\n",
            "Acc: 0.86518 for the XGBClassifier\n",
            "Acc: 0.88235 for the LGBMClassifier\n",
            "Acc: 0.89176 for the EnsembleVoteClassifier\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JApW6PtyluMN"
      },
      "source": [
        "# Lets' try another way"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1pgtJb9jRk_"
      },
      "source": [
        "# MLP with L1 loss for feature selection  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5TVZ0RmKz96",
        "outputId": "4b20bbb2-9c47-4575-b89e-346cf8f1b880",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "np.unique(y_train)"
      ],
      "execution_count": 355,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 355
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X05LsfcUjRyh",
        "outputId": "9f9c2511-0b6b-4ce3-dcbe-0e6f7f39ee5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# device = 'cpu'\n",
        "\n",
        "input_size = 42\n",
        "hidden_size = 32 \n",
        "hidden_size_2 = 10\n",
        "num_classes = np.unique(y_train) # faster to code like a dumbass... len(set(y_train.values.flatten().tolist()))\n",
        "print(f'Number of classes: {np.unique(y_train)}')\n",
        "num_epochs = 5\n",
        "batch_size = 16\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Fully connected neural network with one hidden layer\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.input_size = input_size # ?? \n",
        "        self.l1 = nn.Linear(input_size, hidden_size) \n",
        "        self.l2 = nn.Linear(hidden_size, hidden_size_2)  \n",
        "        self.l3 = nn.Linear(hidden_size_2, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.elu = nn.ELU()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.l3(out)\n",
        "        # no activation and no softmax at the end\n",
        "        return out"
      ],
      "execution_count": 325,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of classes: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po7VpfirjR2L",
        "outputId": "2fbe11f9-fec9-47d8-b3b3-ad85c679ea25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "factor = 0.00005 # reg term coefficient/multiplier/weight  \n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss() # This criterion combines nn.LogSoftmax() and nn.NLLLoss() in one single class.\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
        "\n",
        "# L1 Regularizer\n",
        "l1_reg_criterion = nn.L1Loss() # size_average=False \n",
        "\n",
        "X_train_vals= X_train.values # _RFE\n",
        "y_train_vals = y_train.values.flatten()\n",
        "\n",
        "X_test_vals= X_test.values\n",
        "y_test_vals = y_test.values.flatten()\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    # for i in range(len(X_train_RFE_vals)//100 + 1): #, batch_size\n",
        "\n",
        "    n_correct = 0\n",
        "    n_samples = 0 \n",
        "    for i in range(0, X_train_vals.shape[0], batch_size):\n",
        "\n",
        "        x = torch.as_tensor(X_train_vals[i:i+batch_size], dtype=torch.float).to(device)\n",
        "        y = torch.as_tensor(y_train_vals[i:i+batch_size], dtype=torch.long).to(device)\n",
        "        \n",
        "        outputs = model(x)\n",
        "        loss = criterion(outputs, y)\n",
        "\n",
        "        reg_loss = 0 \n",
        "        for name, param in model.l1.state_dict().items(): # L1 is the first layer \n",
        "          if name == 'weight':\n",
        "            # print(param.size())\n",
        "            # print((param-param).sum().item()); throw_for_bar_after_print_stop\n",
        "            reg_loss = torch.norm(model.l1.state_dict()['weight'], p=1).item() # l1_reg_criterion(param, param-param)\n",
        "        \n",
        "        # print(f'loss: {loss}, reg_loss: {reg_loss}'); throw_for_bar_after_print_stop\n",
        "\n",
        "        loss_pre = loss\n",
        "        loss = loss + (factor * reg_loss)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Train epoch accuracy\n",
        "        _, predicted = torch.max(outputs.data, dim=1)\n",
        "        n_samples += y.size(0)\n",
        "        n_correct += (predicted == y).sum().item()\n",
        "    print(f'Epoch [{epoch}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}, Acc: {100.0 * n_correct / (n_samples+1):.4f}\\t loss: {loss_pre:.4f}, reg_loss: {factor * reg_loss:.5f}')"
      ],
      "execution_count": 335,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Step [206129/206138], Loss: 0.6275, Acc: 73.1526\t loss: 0.6109, reg_loss: 0.01652\n",
            "Epoch [2/5], Step [206129/206138], Loss: 0.5141, Acc: 71.7152\t loss: 0.4943, reg_loss: 0.01984\n",
            "Epoch [3/5], Step [206129/206138], Loss: 0.6434, Acc: 66.8791\t loss: 0.6207, reg_loss: 0.02266\n",
            "Epoch [4/5], Step [206129/206138], Loss: 0.6441, Acc: 63.9103\t loss: 0.6207, reg_loss: 0.02338\n",
            "Epoch [5/5], Step [206129/206138], Loss: 0.6423, Acc: 63.9074\t loss: 0.6187, reg_loss: 0.02369\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5SPcmAFjR5l",
        "outputId": "cef0f0ef-a4cc-4daf-e2be-7c96c0b66454",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "X_test_vals= X_test.values # _RFE\n",
        "y_test_vals = y_test.values.flatten()\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0 \n",
        "    # for i in range(len(X_train_RFE_vals)//100 + 1):   \n",
        "    for i in range(0, X_test_RFE_vals.shape[0], batch_size):\n",
        "        x = torch.as_tensor(X_test_vals[i:i+batch_size], dtype=torch.float).to(device)\n",
        "        y = torch.as_tensor(y_test_vals[i:i+batch_size], dtype=torch.long).to(device)\n",
        "        \n",
        "        outputs = model(x)\n",
        "        if len(outputs.data) > 0:\n",
        "          # max returns (value ,index)\n",
        "          _, predicted = torch.max(outputs.data, dim=1)\n",
        "          \n",
        "          n_samples += y.size(0)\n",
        "          n_correct += (predicted == y).sum().item()\n",
        "\n",
        "        else:\n",
        "          print(\"what???\")\n",
        "          print(x, outputs.data)\n",
        "    acc = 100.0 * n_correct / (n_samples+1)\n",
        "    print(f'Accuracy of the network: {acc} %')"
      ],
      "execution_count": 336,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network: 63.88155852219808 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HMfAuoOjSAq"
      },
      "source": [
        "> Accuracy of the network: 79.64342818112668 %"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3yKHghIjSEV",
        "outputId": "77fc0cf6-57b5-4c5a-f745-ecf059f241c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# print(model)\n",
        "# print(model.l1)\n",
        "# for name, param in model.l1.state_dict().items(): # L1 is the first layer \n",
        "#   if name == 'weight': \n",
        "#     for param_ in param.T:\n",
        "#       print(param_.sum().item())\n",
        "\n",
        "weights = [weight.sum().item() for weight in model.l1.state_dict()['weight'].T]\n",
        "weights = [round(abs(i), 5) for i in weights]\n",
        "weights = np.array(weights/np.sum(weights))\n",
        "weights_idx = np.argsort(fi)[::-1]\n",
        "\n",
        "\n",
        "print(f\"[MLP] Top ten feature weights:  {weights[:10]}\")\n",
        "print(f\"[MLP] Top ten feature indexes:  {weights_idx[:10]}\")\n",
        "print(f\"[MLP] Last ten feature indexes: {weights_idx[-10:]}\\n\")\n",
        "\n",
        "\n",
        "clf = DecisionTreeClassifier()\n",
        "_ = clf.fit(X_train, y_train)\n",
        "fi = [round(i, 5 ) for i in clf.feature_importances_] # round \n",
        "fi = np.array(fi) # to array \n",
        "fi = fi/np.sum(fi) # ensure it's normalize\n",
        "fi_idx = np.argsort(fi)[::-1] # from largest to smallest\n",
        "\n",
        "# print(fi[fi_idx])\n",
        "print(f\"[DecisionTreeClassifier] Top ten feature indexes:  {fi_idx[:10]}\")\n",
        "print(f\"[DecisionTreeClassifier] Last ten feature indexes: {fi_idx[-10:]}\")"
      ],
      "execution_count": 356,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[MLP] Top ten feature weights:  [0.01252026 0.00658208 0.02404366 0.04574006 0.01802584 0.02314406\n",
            " 0.02250805 0.04280177 0.01996318 0.03054257]\n",
            "[MLP] Top ten feature indexes:  [ 9 24 26 35  6 40 30  7 27 15]\n",
            "[MLP] Last ten feature indexes: [28  3 14 10 31 37 19 36 22 41]\n",
            "\n",
            "[DecisionTreeClassifier] Top ten feature indexes:  [ 9 24 26 35  6 40 30  7 27 15]\n",
            "[DecisionTreeClassifier] Last ten feature indexes: [28  3 14 31 10 36 22 37 19 41]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuaTFpTeCgG0"
      },
      "source": [
        "```\n",
        "factor = 0.0\n",
        "[MLP] Top ten feature indexes:  [ 9 24 26 35  6 40 30  7 27 15]\n",
        "[MLP] Top ten feature weights:  [0.06196863 0.02227446 0.04971818 0.02841482 0.04204971 0.02587458 0.04431207 0.02130464 0.01099255 0.00912548]\n",
        "[MLP] Last ten feature indexes: [ 5  3 14 28 36 10 37 19 22 41]\n",
        "```\n",
        "\n",
        "```\n",
        "factor = 0.00005\n",
        "[MLP] Top ten feature indexes:  [ 9 24 26 35  6 40 30  7 27 15]\n",
        "[MLP] Top ten feature weights:  [0.03054257 0.0136881  0.03092274 0.00804256 0.02250805 0.006705 0.00787411 0.04280177 0.05547793 0.03282484]\n",
        "[MLP] Last ten feature indexes: [31  3  5 14 37 36 10 19 22 41]\n",
        "```\n",
        "Overkill... 0.0005 is too high\n",
        "```\n",
        "Epoch [1/5], Step [206129/206138], Loss: 0.6786, Acc: 72.8474\t loss: 0.4932, reg_loss: 0.18541\n",
        "Epoch [3/5], Step [206129/206138], Loss: 0.7730, Acc: 65.8260\t loss: 0.5133, reg_loss: 0.25978\n",
        "\n",
        "factor = 0.0005\n",
        "[MLP] Top ten feature indexes:  [ 9 24 26 35  6 40 30  7 27 15]\n",
        "[MLP] Top ten feature weights:  [0.04053201 0.0279744  0.03267631 0.00767643 0.0375806  0.00558694 0.01319869 0.04616321 0.00876322 0.01025393]\n",
        "[MLP] Last ten feature indexes: [ 5  3 14 31 10 36 37 19 22 41]\n",
        "```\n",
        "\n",
        "# Conclusion\n",
        "\n",
        "Doesn't seem to be very useful here. Maybe its because we have **A lot** of data.\n",
        "\n",
        "* Too bad I made these chances by hand. I could explore more\n",
        "* I should have set the seed\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixQ7uR00jSIB"
      },
      "source": [
        ""
      ],
      "execution_count": 338,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OHfbx1qjSLS"
      },
      "source": [
        ""
      ],
      "execution_count": 338,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twvrr6d5jSOq"
      },
      "source": [
        ""
      ],
      "execution_count": 338,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8gsbiYtjSRk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1T_uPrDSjRop"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmvwsp-KnNWi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJY4PEQhnNb5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkbExAc-nNfp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2aaz0iLnNja"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v30s7FidnNm-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARG5tDbjnNqa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74QP1VY6nNth"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mohA8IeSnNw7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-Jf6wmTnN0B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVGSOxgunN3S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkcSDGFhnN6H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMKSBLJknN8i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuYFI1JRJt6k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}